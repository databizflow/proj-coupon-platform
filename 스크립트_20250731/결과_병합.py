import pandas as pd
import os

def merge_all_results():
    print("ğŸ”„ ë¶„í•  ì²˜ë¦¬ ê²°ê³¼ë§Œ ë³‘í•© ì‹œì‘!")
    print("=" * 60)
    
    # ë¶„í•  ì²˜ë¦¬ ê²°ê³¼ë“¤ ì½ê¸° (6,169ê°œ)
    print("\nğŸ“ ë¶„í•  ì²˜ë¦¬ ê²°ê³¼ë“¤ ì½ê¸°...")
    all_chunks = []
    total_chunk_count = 0
    
    for i in range(1, 8):  # 1~7
        chunk_file = f'ì™„ë£Œ_ë¶„í• _{i:02d}.csv'
        if os.path.exists(chunk_file):
            chunk_df = pd.read_csv(chunk_file, encoding='utf-8-sig')
            chunk_processed = chunk_df[chunk_df['í˜„ëŒ€ì¹´ë“œ_ê°€ë§¹ì—¬ë¶€'].notna() & (chunk_df['í˜„ëŒ€ì¹´ë“œ_ê°€ë§¹ì—¬ë¶€'] != '')]
            all_chunks.append(chunk_processed)
            total_chunk_count += len(chunk_processed)
            print(f"   âœ… ì²­í¬ {i}: {len(chunk_processed)}ê°œ")
        else:
            print(f"   âš ï¸  ì²­í¬ {i}: íŒŒì¼ ì—†ìŒ")
    
    print(f"\nğŸ“Š ë¶„í•  ì²˜ë¦¬ ì´í•©: {total_chunk_count}ê°œ")
    
    # 3. ë¶„í•  ê²°ê³¼ë“¤ë§Œ ë³‘í•©
    print("\nğŸ”„ ë¶„í•  ê²°ê³¼ë“¤ ë³‘í•© ì¤‘...")
    
    # ë¶„í•  ê²°ê³¼ë“¤ë§Œ í•©ì¹˜ê¸°
    merged_df = pd.concat(all_chunks, ignore_index=True)
    
    print(f"   âœ… ë³‘í•© ì™„ë£Œ: {len(merged_df)}ê°œ")
    
    # 4. ì¤‘ë³µ ì œê±° (í˜¹ì‹œ ìˆì„ ìˆ˜ ìˆëŠ”)
    print("\nğŸ” ì¤‘ë³µ ê²€ì‚¬ ë° ì œê±°...")
    before_dedup = len(merged_df)
    merged_df = merged_df.drop_duplicates(subset=['ì‚¬ì—…ìë“±ë¡ë²ˆí˜¸', 'ìƒí˜¸ëª…'], keep='first')
    after_dedup = len(merged_df)
    
    if before_dedup != after_dedup:
        print(f"   âš ï¸  ì¤‘ë³µ ì œê±°: {before_dedup - after_dedup}ê°œ")
    else:
        print(f"   âœ… ì¤‘ë³µ ì—†ìŒ")
    
    # 5. ê²°ê³¼ í†µê³„
    print("\nğŸ“Š ìµœì¢… ê²°ê³¼ í†µê³„:")
    result_counts = merged_df['í˜„ëŒ€ì¹´ë“œ_ê°€ë§¹ì—¬ë¶€'].value_counts()
    
    total_processed = len(merged_df)
    for result, count in result_counts.items():
        percentage = (count / total_processed) * 100
        if result == 'O':
            print(f"   âœ… í˜„ëŒ€ì¹´ë“œ ê°€ë§¹ì : {count:,}ê°œ ({percentage:.1f}%)")
        elif result == 'X':
            print(f"   âŒ ë¹„ê°€ë§¹ì : {count:,}ê°œ ({percentage:.1f}%)")
        else:
            print(f"   âš ï¸  {result}: {count:,}ê°œ ({percentage:.1f}%)")
    
    # 6. ìµœì¢… íŒŒì¼ ì €ì¥
    output_file = 'í˜„ëŒ€ì¹´ë“œ_ê°€ë§¹ì _ì¡°íšŒê²°ê³¼_ìµœì¢…ì™„ë£Œ.csv'
    merged_df.to_csv(output_file, index=False, encoding='utf-8-sig')
    
    print(f"\nğŸ’¾ ìµœì¢… íŒŒì¼ ì €ì¥ ì™„ë£Œ!")
    print(f"ğŸ“ íŒŒì¼ëª…: {output_file}")
    print(f"ğŸ“Š ì´ ì²˜ë¦¬ ê±´ìˆ˜: {len(merged_df):,}ê°œ")
    
    # 7. ì›ë³¸ ë°ì´í„°ì™€ ë¹„êµ
    print("\nğŸ” ì›ë³¸ ë°ì´í„°ì™€ ë¹„êµ:")
    try:
        original_df = pd.read_csv('suji_filtered.csv', encoding='utf-8-sig')
        original_count = len(original_df)
        processed_count = len(merged_df)
        coverage = (processed_count / original_count) * 100
        
        print(f"   ğŸ“‹ ì›ë³¸ ë°ì´í„°: {original_count:,}ê°œ")
        print(f"   âœ… ì²˜ë¦¬ ì™„ë£Œ: {processed_count:,}ê°œ")
        print(f"   ğŸ“ˆ ì²˜ë¦¬ìœ¨: {coverage:.1f}%")
        
        if coverage < 100:
            remaining = original_count - processed_count
            print(f"   âš ï¸  ë¯¸ì²˜ë¦¬: {remaining:,}ê°œ")
    except:
        print("   âš ï¸  ì›ë³¸ íŒŒì¼ ë¹„êµ ë¶ˆê°€")
    
    print("\n" + "=" * 60)
    print("ğŸ‰ ëª¨ë“  ë³‘í•© ì‘ì—…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
    print("=" * 60)
    
    return output_file

if __name__ == "__main__":
    try:
        result_file = merge_all_results()
        print(f"\nğŸŠ ìµœì¢… ê²°ê³¼ íŒŒì¼: {result_file}")
        print("ğŸ“‹ ì´ì œ ì´ íŒŒì¼ë¡œ í˜„ëŒ€ì¹´ë“œ ê°€ë§¹ì  í˜„í™©ì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!")
        
    except Exception as e:
        print(f"\nâŒ ë³‘í•© ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()